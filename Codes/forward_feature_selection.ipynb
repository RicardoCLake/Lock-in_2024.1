{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, precision_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\", index_col=0)\n",
    "min_value = data.iloc[:, 5:].min().min()\n",
    "data = data.fillna(min_value - 1)\n",
    "data.iloc[:, 5:] = data.iloc[:, 5:] + (min_value - 1)*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mac_relation = pd.read_csv(\"mac_name_relation.csv\", index_col=0)\n",
    "good_aps = name_mac_relation[name_mac_relation['ap_name'].isin( [\"Guest-CentraleSupelec\", \"eduroam\", 'stop&go', 'CD91', 'fabrique2024'])][\"ap_mac\"].to_list()\n",
    "columns_to_maintain  = good_aps + data.columns[:5].to_list()\n",
    "data = data[data.columns.intersection(columns_to_maintain)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_columns = list(data.columns[5:])\n",
    "data = data[data[\"room_part\"] != 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tloc Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gamma\n",
    "from scipy.special import hyp2f1\n",
    "\n",
    "import scipy\n",
    "\n",
    "class TLoc:\n",
    "\n",
    "    def __init__(self, train_data: pd.DataFrame):\n",
    "        # self.non_null_minimum_percentage = 0.1\n",
    "        self.train_data = train_data\n",
    "        # self.aps = self.get_aps_with_non_zero_minimum_percentage(self.train_data)\n",
    "        self.aps = list(self.train_data.columns[1:])\n",
    "        if len(self.aps) == 1:\n",
    "            self.max_power = int(self.train_data[self.aps].max())\n",
    "        else:\n",
    "            self.max_power = int(self.train_data[self.aps].max().max())\n",
    "\n",
    "\n",
    "        self.spaces = list(self.train_data[\"room\"].unique())\n",
    "\n",
    "        self.power_probability_masks = {}\n",
    "        self.power_prior_probability_distribution = {}\n",
    "        self.eps = 1e-5\n",
    "\n",
    "\n",
    "    def get_aps_with_non_zero_minimum_percentage(self, data):\n",
    "        percentage_of_non_zeros = (data.iloc[:, 5:] != 0).sum() / data.shape[0]\n",
    "        return data.columns[5:][percentage_of_non_zeros >= self.non_null_minimum_percentage]\n",
    "    \n",
    "\n",
    "\n",
    "    def get_mu_and_phi_estimation(self, data, router):\n",
    "        mu = []\n",
    "        phi = []\n",
    "        data_of_router = data[[\"room\", router]]\n",
    "        for space in self.spaces:\n",
    "            data_of_router_in_space = data_of_router[data_of_router[\"room\"] == space]\n",
    "\n",
    "            data_of_router_in_space_without_zero_values = data_of_router_in_space[data_of_router_in_space[router] != 0]\n",
    "            if len(data_of_router_in_space_without_zero_values) == 0:\n",
    "                mu.append(0.0)\n",
    "            else:\n",
    "                mu.append(data_of_router_in_space_without_zero_values[router].mean())\n",
    "            phi.append(1 - data_of_router_in_space_without_zero_values.shape[0] / data_of_router_in_space.shape[0])\n",
    "\n",
    "        return mu, phi\n",
    "\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        for router in self.aps:\n",
    "\n",
    "\n",
    "            self.power_probability_masks[router] = {}\n",
    "            self.power_prior_probability_distribution[router] = {}\n",
    "\n",
    "            mu, phi = self.get_mu_and_phi_estimation(self.train_data, router)\n",
    "\n",
    "\n",
    "            total_num_samples_in_router = self.train_data[router].shape[0]\n",
    "            for power in range(0, self.max_power):\n",
    "                self.power_probability_masks[router][\n",
    "                    power] = self.approximate_position_density_function_given_router(power, np.array(mu),\n",
    "                                                                                    np.array(phi))\n",
    "                num_samples_with_value_power_in_router = (self.train_data[router] == power).sum()\n",
    "\n",
    "                self.power_prior_probability_distribution[router][\n",
    "                    power] = num_samples_with_value_power_in_router / total_num_samples_in_router\n",
    "\n",
    "                    \n",
    "\n",
    "    def cumulative_distribution_function_of_t_student(self, x, v):\n",
    "\n",
    "        return 0.5 + x * gamma((v + 1) / 2) * hyp2f1(1 / 2, (v + 1) / 2, 3 / 2, -(x ** 2) / v) / (\n",
    "                np.sqrt(v * np.pi) * gamma(v / 2))\n",
    "    \n",
    "    def cumulative_distribution_function_of_power(self, power, mu, phi, sigma, v):\n",
    "\n",
    "        cdf = phi * np.heaviside(power, 1) + (1 - phi) * self.cumulative_distribution_function_of_t_student(\n",
    "            (power - mu) / sigma, v)\n",
    "        \n",
    "        return cdf\n",
    "    \n",
    "\n",
    "    def approximate_position_density_function_given_router(self, power, mu, phi, sigma=5, num_samples_per_ap=30, t_score_alpha=0.05):\n",
    "\n",
    "        v = np.ceil(num_samples_per_ap * (1 - phi) - 1)\n",
    "        v = np.where(v <= 0, 1, v)\n",
    "\n",
    "        t_score = scipy.stats.t.ppf(0.5 + t_score_alpha, v)\n",
    "\n",
    "        density_function = self.cumulative_distribution_function_of_power(power + t_score * sigma, mu, phi, sigma, v) - self.cumulative_distribution_function_of_power(\n",
    "                    power - t_score * sigma, mu, phi, sigma, v)  # power, mu, phi, sigma, v\n",
    "\n",
    "        return density_function\n",
    "    \n",
    "\n",
    "    def pred(self, X_test):\n",
    "\n",
    "        y_pred = []\n",
    "        min_prob = self.eps * np.ones(len(self.spaces))\n",
    "\n",
    "        for _, test_sample in X_test.iterrows():\n",
    "\n",
    "            distribution_xy_given_bf = np.ones(len(self.spaces))\n",
    "\n",
    "            for router in self.aps:\n",
    "\n",
    "                    power = int(test_sample[router])\n",
    "\n",
    "                    try:\n",
    "                        prob_p_given_xybfr = self.power_probability_masks[router][power]\n",
    "                    except KeyError:\n",
    "                        # print(f\"Error predicting router {router}, power {power}\")\n",
    "                        continue\n",
    "                    \n",
    "\n",
    "\n",
    "                    prob_p_given_xybfr = np.maximum(prob_p_given_xybfr, min_prob)\n",
    "                    #prob_p_given_xybfr = prob_p_given_xybfr / prob_p_given_xybfr.sum()\n",
    "                    #prob_xy_given_pbfr = prob_p_given_xybfr / (\n",
    "                    #                tloc.eps + tloc.power_prior_probability_distribution[router][power])\n",
    "\n",
    "\n",
    "                    distribution_xy_given_bf = distribution_xy_given_bf * prob_p_given_xybfr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            room_pred = self.spaces[distribution_xy_given_bf.argmax()]\n",
    "            y_pred.append(room_pred)\n",
    "\n",
    "        y_pred = np.array(y_pred)\n",
    "        ground_truth = np.array(list(X_test[\"room\"]))\n",
    "        ac = np.sum(y_pred == ground_truth)/len(ground_truth)\n",
    "        return ac, y_pred, ground_truth\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = data[data[\"device_id\"] != \"G\"]\n",
    "\n",
    "\n",
    "val_data ,test_data = train_test_split(data[data[\"device_id\"] == \"G\" ], test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features_for_guilherme = ['room',\n",
    " '94:d4:69:fd:b1:e6:',\n",
    " '94:d4:69:f9:7e:47:',\n",
    " '94:d4:69:f9:7f:c9:',\n",
    " '94:d4:69:f9:7d:6f:',\n",
    " '94:d4:69:f9:7d:c4:',\n",
    " '94:d4:69:fd:ac:e8:',\n",
    " '94:d4:69:f9:5b:e0:',\n",
    " '94:d4:69:fd:b1:07:',\n",
    " '94:d4:69:f6:c5:63:',\n",
    " '94:d4:69:fa:99:00:',\n",
    " '94:d4:69:fd:ae:c3:',\n",
    " '94:d4:69:fd:b1:0f:',\n",
    " '70:f3:5a:96:66:e4:',\n",
    " '94:d4:69:f6:e4:e8:',\n",
    " '94:d4:69:fd:b1:06:',\n",
    " '94:d4:69:f9:7f:c7:',\n",
    " '94:d4:69:f6:c5:6b:',\n",
    " 'a4:88:73:4e:40:c0:',\n",
    " '94:d4:69:f6:b3:e0:',\n",
    " '94:d4:69:f7:90:88:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = [\"room\",\n",
    "   ]\n",
    "\n",
    "\n",
    "remaining_features = AP_columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for aff in range(20):\n",
    "    best_acc = -1\n",
    "    best_feature = None\n",
    "    best_feature_index = None\n",
    "\n",
    "    for i, feature in enumerate(remaining_features):\n",
    "        features_to_use = best_features + [feature]\n",
    "        X_train_subset = train_data[features_to_use]\n",
    "        X_test_subset = val_data[features_to_use]\n",
    "        model = TLoc(X_train_subset)\n",
    "        \n",
    "        model.train()\n",
    "        acc, a, b = model.pred(X_test_subset)\n",
    "\n",
    "\n",
    "        if acc > best_acc:\n",
    "            print(best_acc)\n",
    "            best_acc = acc\n",
    "            best_feature = feature\n",
    "            best_feature_index = i\n",
    "\n",
    "    print(aff)\n",
    "    print(best_feature)\n",
    "\n",
    "    best_features.append(best_feature)\n",
    "    remaining_features = np.delete(remaining_features, best_feature_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TLoc(train_data[best_features_for_guilherme])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07928679817905918,\n",
       " array(['LC410', 'LC410', 'LC410', ..., 'LC410', 'LC410', 'LC410'],\n",
       "       dtype='<U5'),\n",
       " array(['LC410', 'LC413', 'LC448', ..., 'LC414', 'LC414', 'LC414'],\n",
       "       dtype='<U5'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pred(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LC410', 'LC413', 'LC448', 'LC455', 'LC426', 'LC443', 'LC416',\n",
       "       'LC414', 'LC415', 'LC412', 'LC424', 'LC437', 'LC442', 'LC417'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"room\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LC416', 'LC412', 'LC414', 'LC442', 'LC426', 'LC437', 'LC455',\n",
       "       'LC410', 'LC424', 'LC415', 'LC443', 'LC417', 'LC448', 'LC413'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[\"room\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
